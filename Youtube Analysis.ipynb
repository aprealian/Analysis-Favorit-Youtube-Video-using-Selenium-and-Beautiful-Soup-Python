{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import json\n",
    "import requests as reqs\n",
    "from altair import Row, Column, Chart, Text, Scale, Color\n",
    "import pandas as pd\n",
    "import csv\n",
    "from itertools import islice\n",
    "import ast\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    def __init__(self, idx, title, description, date, channelID, channel, categoryID, tags):\n",
    "        self.idx = idx\n",
    "        self.title = title\n",
    "        self.description = description\n",
    "        self.date = date\n",
    "        self.channelID = channelID\n",
    "        self.channel = channel\n",
    "        self.categoryID = categoryID\n",
    "        self.tags = tags\n",
    "    def asList(self):\n",
    "        return [\n",
    "            self.idx, \n",
    "            self.title,\n",
    "            self.description,\n",
    "            self.date,\n",
    "            self.channelID,\n",
    "            self.channel,\n",
    "            self.categoryID,\n",
    "            self.tags\n",
    "        ]\n",
    "    \n",
    "    \n",
    "def get_data(totalVideo, perPage, channelID, youtubeAPIKEY):\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/aprilian/Downloads/chromedriver')\n",
    "    driver.get(\"https://www.youtube.com/channel/\"+channelID+\"/videos?view=15&flow=grid\")\n",
    "\n",
    "    maxIterate = int(totalVideo/perPage)\n",
    "\n",
    "    elem = driver.find_element_by_tag_name('html')\n",
    "    for i in range(0,maxIterate):\n",
    "        elem.send_keys(Keys.END)\n",
    "        time.sleep(5)\n",
    "        \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    videos = []\n",
    "    videoList = []\n",
    "    for tag in soup.find_all(\"a\", {'id':['video-title']}, href=True):\n",
    "        url = tag['href']\n",
    "        videoID = remove_prefix(url, '/watch?v=')\n",
    "        video = get_video_detail(youtubeAPIKEY, videoID)\n",
    "        videos.append(video)\n",
    "        videoList.append(video.asList())\n",
    "        \n",
    "    with open('My-Youtube-Data.csv', 'a') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(videoList)\n",
    "    csvFile.close()\n",
    "    \n",
    "    return videos\n",
    "        \n",
    "def get_video_detail(youtubeAPIKEY, videoID):\n",
    "    response = reqs.get('https://www.googleapis.com/youtube/v3/videos?id='+videoID+'&key='+youtubeAPIKEY+'&part=snippet,contentDetails,statistics,status&hl=id')\n",
    "    response_dict = json.loads(response.text)\n",
    "\n",
    "    item = response_dict['items'][0]\n",
    "    snippet = item['snippet']\n",
    "    vid_id = item['id']\n",
    "    vid_title = snippet['title']\n",
    "    vid_date = snippet['publishedAt']\n",
    "    vid_desc = snippet['description']\n",
    "    vid_channelID = snippet['channelId']\n",
    "    vid_channel = snippet['channelTitle']\n",
    "    vid_categoryId = snippet['categoryId']\n",
    "    vid_tags = snippet.get('tags')\n",
    "    \n",
    "    return Video(vid_id, vid_title, vid_desc, vid_date, vid_channelID, vid_channel, vid_categoryId, vid_tags)\n",
    "    \n",
    "    \n",
    "def remove_prefix(text, prefix):\n",
    "    if text.startswith(prefix): \n",
    "         text = text.replace(prefix, \"\", 1)\n",
    "    return text\n",
    "\n",
    "def result_by_title(videos, youtubeAPIKEY):\n",
    "    \n",
    "    text = ''\n",
    "    counts = dict()\n",
    "    for vid in videos:\n",
    "        title = re.sub('\\W+',' ', vid.title.lower())\n",
    "        title = ' '.join( [w for w in title.split() if len(w)>1] )\n",
    "        title = title.split()\n",
    "        title = [word for word in title if word not in get_stop_words('en')]\n",
    "        title = [word for word in title if word not in get_stop_words('id')]\n",
    "        \n",
    "        text += ' '.join(title)\n",
    "        \n",
    "        for t in title:\n",
    "            counts[t] = counts.get(t, 0) + 1\n",
    "            \n",
    "    getWordCloud(text)\n",
    "    \n",
    "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    words = dict()\n",
    "    for c in counts:\n",
    "        words[c[0]] = c[1]\n",
    "        \n",
    "    \n",
    "    MAX_RESULTS = 18\n",
    "    words = {k: words[k] for k in list(words.keys())[:MAX_RESULTS]} \n",
    "        \n",
    "    #change dictionary into dataframe \n",
    "    print(\"======== Title Most Likely ========\")\n",
    "    plt.figure(figsize=(10,10)) \n",
    "    dfY = pd.Series(words, name='Title')\n",
    "    \n",
    "    #show data as chart\n",
    "    ax = dfY.plot.barh(x='lab', y='val', rot=0)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def result_by_category(videos, youtubeAPIKEY):\n",
    "    counts = dict()\n",
    "    for vid in videos:\n",
    "        counts[vid.categoryID] = counts.get(vid.categoryID, 0) + 1\n",
    "        \n",
    "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    categories = dict()\n",
    "    for r in counts:\n",
    "        response = reqs.get('https://www.googleapis.com/youtube/v3/videoCategories?id='+r[0]+'&key='+youtubeAPIKEY+'&part=snippet&hl=id')\n",
    "        response_dict = json.loads(response.text)\n",
    "        category = response_dict['items'][0]['snippet']['title']\n",
    "        categories[category] = r[1]\n",
    "\n",
    "    #change dictionary into dataframe \n",
    "    print(\"======== Category Most Likely ========\")\n",
    "    plt.figure(figsize=(10,10))\n",
    "    dfX = pd.Series(categories, name='Category')\n",
    "    \n",
    "    #show data as chart\n",
    "    ax = dfX.plot.barh(x='lab', y='val', rot=0) \n",
    "    plt.show()\n",
    "        \n",
    "    #return categories\n",
    "\n",
    "\n",
    "\n",
    "def result_by_channel(videos):\n",
    "    counts = dict()\n",
    "    for vid in videos:\n",
    "        counts[vid.channel] = counts.get(vid.channel, 0) + 1\n",
    "        \n",
    "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    channels = dict()\n",
    "    for c in counts:\n",
    "        channels[c[0]] = c[1]\n",
    "        \n",
    "    \n",
    "    MAX_RESULTS = 18\n",
    "    channels = {k: channels[k] for k in list(channels.keys())[:MAX_RESULTS]} \n",
    "        \n",
    "    #change dictionary into dataframe \n",
    "    print(\"======== Channel Most Likely ========\")\n",
    "    plt.figure(figsize=(10,10))\n",
    "    dfY = pd.Series(channels, name='Channel')\n",
    "    \n",
    "    #show data as chart\n",
    "    ax = dfY.plot.barh(x='lab', y='val', rot=0) \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    #return channels\n",
    "\n",
    "\n",
    "def result_by_tag(videos):\n",
    "    text = ''\n",
    "    counts = dict()\n",
    "    for vid in videos:\n",
    "\n",
    "        tag = vid.tags\n",
    "        if len(tag) > 0:\n",
    "            tag = ast.literal_eval(tag)\n",
    "            for t in tag:\n",
    "                #print(t)\n",
    "                t = t.lower()\n",
    "                counts[t] = counts.get(t, 0) + 1\n",
    "                text += ''.join(t)\n",
    "                \n",
    "                #tList = t.split()\n",
    "                #for t1 in tList: \n",
    "                    #print(t1)\n",
    "                    #counts[t1] = counts.get(t1, 0) + 1\n",
    "                    #text += ''.join(t1)\n",
    "                \n",
    "     \n",
    "    getWordCloud(text)\n",
    "                \n",
    "    \n",
    "    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "        \n",
    "    tags = dict()\n",
    "    for t in counts:\n",
    "        tags[t[0]] = t[1]\n",
    "        \n",
    "    \n",
    "    MAX_RESULTS = 20\n",
    "    tags = {k: tags[k] for k in list(tags.keys())[:MAX_RESULTS]} \n",
    "        \n",
    "    #change dictionary into dataframe \n",
    "    print(\"======== Tags Most Likely ========\")\n",
    "    plt.figure(figsize=(10,10)) \n",
    "    dfY = pd.Series(tags, name='Tags')\n",
    "    \n",
    "    #show data as chart\n",
    "    ax = dfY.plot.barh(x='lab', y='val', rot=2)\n",
    "    plt.show()\n",
    "\n",
    "    #return tags\n",
    "    \n",
    "\n",
    "def loadCSVData():\n",
    "    with open('My-Youtube-Data.csv', 'r') as readFile:\n",
    "        reader = csv.reader(readFile)\n",
    "        data = list(reader)\n",
    "    videos = []\n",
    "    for v in data:\n",
    "        videos.append(Video(v[0], v[1], v[2], v[3], v[4], v[5], v[6], v[7]))\n",
    "    return videos\n",
    "\n",
    "\n",
    "def getWordCloud(text):\n",
    "    d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "    \n",
    "    \n",
    "    filtered_words = list(filter(lambda word: word not in getStopwords(), text))\n",
    "    \n",
    "    # read the mask image\n",
    "    #alice_mask = np.array(Image.open(path.join(d, \"owl.png\")))\n",
    "\n",
    "    stopwords = getStopwords()\n",
    "\n",
    "    wc = WordCloud(background_color=\"white\", max_words=2000,\n",
    "                   stopwords=stopwords, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "    # generate word cloud\n",
    "    wc.generate(text)\n",
    "\n",
    "    # store to file\n",
    "    wc.to_file(path.join(d, \"result.png\"))\n",
    "\n",
    "    # show\n",
    "    plt.figure(figsize=(20,20)) \n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def getStopwords():\n",
    "    # Create stopword list:\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"official\", \"di\"])\n",
    "    return stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubeAPIKEY = '[YOUR_YOUTUBE_API_KEY]'\n",
    "channelID = '[YOUR_CHANNEL_ID]'\n",
    "totalVideo = 1000\n",
    "perPage = 30\n",
    "\n",
    "print(\"starting and getting data...\")\n",
    "\n",
    "#getting data from Internet, but if you have your local data (CSV file command code on below)\n",
    "#videos = get_data(totalVideo, perPage, channelID, youtubeAPIKEY)\n",
    "#load data from local file (CSV)\n",
    "videos = loadCSVData()\n",
    "\n",
    "print(\"processing data...\")\n",
    "\n",
    "result_by_title(videos, youtubeAPIKEY)\n",
    "\n",
    "result_by_category(videos, youtubeAPIKEY)\n",
    "\n",
    "result_by_channel(videos)\n",
    "\n",
    "result_by_tag(videos)\n",
    "\n",
    "print(\"finished...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
